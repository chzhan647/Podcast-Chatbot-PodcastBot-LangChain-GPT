{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "# import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://chartable.com/charts/itunes/us\"\n",
    "\n",
    "    # Opening up connection and grabbing the page\n",
    "url = BASE_URL \n",
    "webpage_data = fetch_webpage_data(url)\n",
    "\n",
    "podcast_data = get_podcast_data(webpage_data)\n",
    "write_to_json_file(podcast_data,'podcast_2024.json')\n",
    "\n",
    "\n",
    "def fetch_webpage_data(url):\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req)\n",
    "    #page = Request('https://healthygirlkitchen.com/category/recipes/', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpageData = webpage.read()\n",
    "    webpage.close()\n",
    "    return webpageData\n",
    "\n",
    "def get_podcast_data(webpage_data):\n",
    "    page_soup = BeautifulSoup(webpage_data, 'html.parser')\n",
    "    podcasts = page_soup.find_all('div', attrs = {\"class\":\"mb3\"})\n",
    "    podcast_lst = ['arts','business','comedy','education','fiction','government','health-fitness','history','kids-family',\n",
    "                    'leisure','music','news','religion-spirituality','science','society-culture','sports'\n",
    "                    ,'tv-film','technology','true-crime']\n",
    "    podcast_cat_list = {}\n",
    "    for i in podcasts[1].findAll('a'):\n",
    "        job_element = i['href']\n",
    "        category_name = job_element.strip().split('/')[-1].split('-')[1]\n",
    "        if category_name == 'arts':\n",
    "            podcast_lst_data = fetch_webpage_data(job_element)\n",
    "            podcast_data_soup = BeautifulSoup(podcast_lst_data, 'html.parser')\n",
    "            podcast_final = list(set([html_string.get_text() for html_string in tb.find_all('a',attrs= {\"class\":\"link blue\"}) for tb in podcast_data_soup.find_all('table')]))\n",
    "            podcast_cat_list[category_name] = podcast_final\n",
    "    return podcast_cat_list\n",
    "\n",
    "def write_to_json_file(data, write_path):\n",
    "    with open(write_path,'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def write_to_yaml_file(data, write_path):\n",
    "    with open(write_path,'w') as f:\n",
    "        yaml.dump(data,f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "page_soup = BeautifulSoup(webpage_data, 'html.parser')\n",
    "podcasts = page_soup.find_all('div', attrs = {\"class\":\"mb3\"})\n",
    "podcast_lst = ['arts','business','comedy','education','fiction','government','health-fitness','history','kids-family',\n",
    "                'leisure','music','news','religion-spirituality','science','society-culture','sports'\n",
    "                ,'tv-film','technology','true-crime']\n",
    "podcast_cat_list = {}\n",
    "for i in podcasts[1].findAll('a'):\n",
    "    job_element = i['href']\n",
    "    category_name = job_element.strip().split('/')[-1].split('-')[1]\n",
    "    if category_name == 'arts':\n",
    "        podcast_lst_data = fetch_webpage_data(job_element)\n",
    "        podcast_data_soup = BeautifulSoup(podcast_lst_data, 'html.parser')\n",
    "        podcast_final = list(set([html_string.get_text() for html_string in tb.find_all('a',attrs= {\"class\":\"link blue\"}) for tb in podcast_data_soup.find_all('table')]))\n",
    "        podcast_cat_list[category_name] = podcast_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_cat_list = {}\n",
    "for i in podcasts[1].findAll('a'):\n",
    "    job_element = i['href']\n",
    "    category_name = job_element.strip().split('/')[-1].split('-')[1]\n",
    "    if category_name == 'arts':\n",
    "        podcast_lst_data = fetch_webpage_data(job_element)\n",
    "        podcast_data_soup = BeautifulSoup(podcast_lst_data, 'html.parser')\n",
    "        podcast_final = list(set([html_string.get_text() for html_string in tb.find_all('a',attrs= {\"class\":\"link blue\"}) for tb in podcast_data_soup.find_all('table')]))\n",
    "        podcast_cat_list[category_name] = podcast_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between the recipe name and its page url.\n",
    "podcast_data = {}\n",
    "for i in podcasts[3].findAll('a'):\n",
    "    job_element = i['href']\n",
    "    category_name = job_element.strip().split('/')[-1].split('-')[1]\n",
    "    if category_name in podcast_lst:\n",
    "        podcast_url = job_element.get('href')\n",
    "        podcast_lst_data = fetch_webpage_data(podcast_url)\n",
    "        podcast_data_soup = BeautifulSoup(podcast_lst_data, 'html.parser')\n",
    "        \n",
    "\n",
    "        podcast_list = [li.text for ultag in podcast_data_soup.find_all('ul',\n",
    "                                                                    attrs={\"class\": \"wprm-recipe-ingredients\"}) for li in ultag.find_all('li')]\n",
    "    recipe_instruction = [li.text for ultag in podcast_data_soup.find_all('ul',\n",
    "                                                                                        attrs={\n",
    "                                                                                            \"class\": \"wprm-recipe-instructions\"})\n",
    "                                for li in ultag.find_all('li')]\n",
    "    podcast_data[category_name] = {}\n",
    "    podcast_data[category_name]['recipe'] = recipe_ingredient_list\n",
    "    podcast_data[category_name]['instruction'] = recipe_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "url = \"https://feeds.simplecast.com/dHoohVNH\"\n",
    "feed = feedparser.parse(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed.feed.title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed.feed.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in feed.feed.tags[0].values():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feed.entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
